<!DOCTYPE html>
<html lang = "en-US">

<head>
    <title> Assignment #1 - 3 </title>   
    <link rel ="stylesheet" href ="asg5_chl533.css" type = "text/css" > 
</head>
    
<body>
    <header><h1> Part 3. Database and Current events </h1></header>
    <h3><a href = "index.html" > <strong> Back to Home</strong> </a></h3>
    <p> Read at least three articles on databases in a current newspaper or journal and write a response of at least a half page to each. Post the URL for each article and your response on a webpage under “Assignment #1″ on your website. In addition to a discussion on the social implications of the usage of databases and “big data”, do your best to identify the technology/technologies used to capture the data if that information is available.
    </p>
    <br>
    <br>
    
    
    
    
    <dt><em> - Facebook execs grilled by investors after data scandal - </em> <a href = "https://money.cnn.com/2018/05/31/technology/facebook-shareholder-meeting/index.html" target="_blank" > Link </a><dt>
        <dd> <p>While other articles I read were implications of databases being leveraged to positively impact society, this was an article that vividly manifests how much influence database wields in current times and at the same time possess massive potential to be abused. In addition, the fact that Facebook’s data scandal wiped away tens of billions of dollars in its market value shines light on the ‘hippocrates's oath’ pertaining to data scientists mentioned in class. Since Facebook is an application of human interaction, relationship and preference databases it is not strange that certain parties want to utilize this data for the desirable outcome. For such reasons Facebook has been implicated in unsolicited political use of data when Cambridge Analytica was revealed to have accessed Facebook’s data in favor of president Donald Trump during his campaign. Another social issue that is affiliated with database is the personalized filters that most IT firms make use of these days including Google, Facebook and most e-commerce companies. ‘Filter Bubbles’ was a term I learned reading this article where due to these well designed algorithms of the filters, people are intellectually isolated. Like always innovative technologies that are invented with good intentions also hold the potential to yield side effects and in the end it is for us to determine how to use it or even whether to use it at all.</p></dd> 
    <br>
    <br>
    

    <dt><em> - As college costs rocket up, unlock the data that will enable smart choices - </em><a href ="https://www-m.cnn.com/2018/08/16/opinions/college-transparency-student-data-cassidy-alexander/index.html?r=https%3A%2F%2Fwww.cnn.com%2Fsearch%2F%3Fq%3Dstatistics%2520data%26size%3D10%26from%3D10%26page%3D2" target="_blank" > Link </a><dt>
        <dd> <p>It was very shocking to read that the average annual cost of college tuition is only $ 5000 than the median household income. Some might misinterpret this as half of households being able to pay for college tuition. However, that is only possible if they spend their entire money solely on education and nothing else. For some, entering college might be a huge investment not only for them but also their family. Until now due to the College Transparency Act (CTA) data regarding students were very limited. However, soon the revised CTA will disclose these which will be managed by the National Center for Education Statistics. Colleges being classified as higher education and being a significant part of society I personally think the data that will be open to public will not only aid individuals but also be utilized to sophisticate research in the field of education. On the top of my head, publication of these data will give rise to algorithms for college recommendation as well as advising services for what to prepare for a certain college if data shows that the school has an inclination to applicants with certain traits and experiences. 
        </p></dd>
     <br>
     <br>
    
    
     <dt><em> - 'Statistically, it's coming.' California prepares for the next big earthquake - </em><a href =https://www.cnn.com/2017/09/30/us/california-earthquake-preparation/index.html target="_blank" > Link </a><dt>
    
        <dd><p> I think this really shows an example of data being used in a bigger level for the better. Data regarding earthquake magnitudes, epicenters and damages have been available for quite a while but couldn’t really have significance because we were able to get the numbers while it was happening leaving us with no tools to prevent or effectively prepare for such natural disasters. But entering the 21 century the accumulated data along with technological advances has allowed governments to somewhat predict and effectively prepare for these disasters. A study done in 2008 predicted 99 percent chance of a 6.7 magnitude earthquake hitting California within 30 years. As an aftermath of such findings LA announced regulations regarding retrofitting 14,000 buildings for the safety of the citizens in 2015. On top of that by adopting underground seismometers systems they are able to give warnings before minutes of the actual happening. As data accumulate to form a big database thus providing a bigger pool, regulatory retrofitting can become more efficient and seismometers more precise.  
        </p></dd>
     <br>
     <br>
    
    

    
</body>    
       
